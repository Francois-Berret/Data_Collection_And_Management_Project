{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1MTKUGsTJOqqRnlnhQS-q8Z15Hra-j6LA","authorship_tag":"ABX9TyMrEAecgieJl4ythHobtom2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"kf4LMypU3fXU","executionInfo":{"status":"ok","timestamp":1688288993114,"user_tz":-120,"elapsed":9704,"user":{"displayName":"François Berret","userId":"15987982988001849610"}}},"outputs":[],"source":["!pip install scrapy -q"]},{"cell_type":"code","source":["# cities = [\"Mont Saint Michel\",\n","# \"St Malo\",\n","# \"Bayeux\",\n","# \"Le Havre\",\n","# \"Rouen\",\n","# \"Paris\",\n","# \"Amiens\",\n","# \"Lille\",\n","# \"Strasbourg\",\n","# \"Chateau du Haut Koenigsbourg\",\n","# \"Colmar\",\n","# \"Eguisheim\",\n","# \"Besancon\",\n","# \"Dijon\",\n","# \"Annecy\",\n","# \"Grenoble\",\n","# \"Lyon\",\n","# \"Gorges du Verdon\",\n","# \"Bormes les Mimosas\",\n","# \"Cassis\",\n","# \"Marseille\",\n","# \"Aix en Provence\",\n","# \"Avignon\",\n","# \"Uzes\",\n","# \"Nimes\",\n","# \"Aigues Mortes\",\n","# \"Saintes Maries de la mer\",\n","# \"Collioure\",\n","# \"Carcassonne\",\n","# \"Ariege\",\n","# \"Toulouse\",\n","# \"Montauban\",\n","# \"Biarritz\",\n","# \"Bayonne\",\n","# \"La Rochelle\"]"],"metadata":{"id":"Ioq1sdkbCE-C","executionInfo":{"status":"ok","timestamp":1688288993116,"user_tz":-120,"elapsed":11,"user":{"displayName":"François Berret","userId":"15987982988001849610"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["import os\n","import logging\n","\n","import scrapy\n","from scrapy.crawler import CrawlerProcess\n","\n","# class BookingSpider(scrapy.Spider):\n","#     # Name of your spider\n","#     name = \"booking\"\n","\n","#     def start_requests(self):\n","#         url = \"https://www.booking.com/searchresults.fr.html?ss=Collioure%2C+Languedoc-Roussillon%2C+France&ssne=La+Rochelle&ssne_untouched=La+Rochelle&label=gen173nr-1FCAQoggJCEHNlYXJjaF9jb2xsaW91cmVIDVgEaE2IAQGYAQ24ARfIAQzYAQHoAQH4AQOIAgGoAgO4ArH5hKUGwAIB0gIkZTFmNTdhNjUtNTM5OS00OWJiLTg5YmMtZjA1ZmE5NDFjNjY02AIF4AIB&sid=2dc49d41029254b93a72b7a8bf7f28af&aid=304142&lang=fr&sb=1&src_elem=sb&src=index&dest_id=-1421032&dest_type=city&ac_position=0&ac_click_type=b&ac_langcode=fr&ac_suggestion_list_length=5&search_selected=true&search_pageview_id=60d33f665ac100cd&ac_meta=GhA2MGQzM2Y2NjVhYzEwMGNkIAAoATICZnI6CUNvbG9pb3VyZUABSgljb2xsaW91cmVQww4%3D&group_adults=2&no_rooms=1&group_children=0&sb_travel_purpose=leisure\"\n","#         yield scrapy.Request(url=url, callback=self.parse)\n","\n","    # # Starting URL\n","    # start_urls = ['https://www.booking.com/searchresults.fr.html?ss=La+Rochelle&ssne=La+Rochelle&ssne_untouched=La+Rochelle&label=gog235jc-1DCAEoggI46AdIDVgDaE2IAQGYAQ24ARfIAQzYAQPoAQH4AQKIAgGoAgO4AoDuhKUGwAIB0gIkOTVhMDk2MDItNWFmNS00MTgzLThmZmQtYmNiMDVjNmExY2M52AIE4AIB&sid=2dc49d41029254b93a72b7a8bf7f28af&aid=397594&lang=fr&sb=1&src_elem=sb&src=index&dest_id=-1438604&dest_type=city&group_adults=2&no_rooms=1&group_children=0&sb_travel_purpose=leisure']\n","\n","    # # # Parse function for form request\n","    # def parse(self, response):\n","    #         return scrapy.FormRequest.from_response(\n","    #             response,\n","    #             formdata={\"ss\":\"La Rochelle\"},\n","    #             callback=self.scrape_results\n","    #         )\n","\n","class BookingSpider(scrapy.Spider):\n","    name = 'booking'\n","    start_urls = ['https://www.booking.com/index.fr.html']\n","\n","    def parse(self, response):\n","        {\n","        'hotel_names' : response.xpath('//*[@id=\"indexsearch\"]/div[1]/div/div/div[2]/div[1]/p/text()').get()\n","        }\n","        # for name in hotel_names:\n","        #     yield {\n","        #         'hotel_name': name.strip()\n","        #     }\n","\n","    # def scrape_results(self, response):\n","    #     yield {\n","    #         \"nb_ets\" : response.xpath('//*[@id=\"search_results_table\"]/div[2]/div/div/div[3]/div[4]/div[1]/div[2]/div/div/div/div[1]/div/div[3]/text()').get(),\n","    #         \"nom1\" : response.xpath('//*[@id=\"search_results_table\"]/div[2]/div/div/div[3]/div[2]/div[1]/div[2]/div/div/div/div[1]/div/div[1]/div[1]/h3/a/div[1]/text()').get(),\n","    #         \"city_booking_url\" : response.xpath('//*[@id=\"bodyconstraint-inner\"]/div[1]/div/div/nav/ol/li[3]').attrib[\"href\"]\n","    #         }\n","\n","# Name of the file where the results will be saved\n","filename = \"Kayak_Project_Scraped_URLS9.json\"\n","\n","# If file already exists, delete it before crawling (because Scrapy will concatenate the last and new results otherwise)\n","if filename in os.listdir('/content/drive/MyDrive/Jedha_Fullstack/Data_Collection_and_Management/Web_Scraping/'):\n","        os.remove('/content/drive/MyDrive/Jedha_Fullstack/Data_Collection_and_Management/Web_Scraping/' + filename)\n","\n","# Declare a new CrawlerProcess with some settings\n","process = CrawlerProcess(settings = {\n","    'USER_AGENT': 'Chrome/97.0',\n","    'LOG_LEVEL': logging.INFO,\n","    \"FEEDS\": {\n","        '/content/drive/MyDrive/Jedha_Fullstack/Data_Collection_and_Management/Web_Scraping/' + filename: {\"format\": \"json\"},\n","    }\n","})\n","\n","# Start the crawling using the spider you defined above\n","process.crawl(BookingSpider)\n","process.start()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XoI5c22j3hzR","executionInfo":{"status":"ok","timestamp":1688288995678,"user_tz":-120,"elapsed":2570,"user":{"displayName":"François Berret","userId":"15987982988001849610"}},"outputId":"79752bab-f82b-4d04-8aae-939878731839"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:scrapy.utils.log:Scrapy 2.9.0 started (bot: scrapybot)\n","2023-07-02 09:09:52 [scrapy.utils.log] INFO: Scrapy 2.9.0 started (bot: scrapybot)\n","INFO:scrapy.utils.log:Versions: lxml 4.9.2.0, libxml2 2.9.14, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.1, Twisted 22.10.0, Python 3.10.12 (main, Jun  7 2023, 12:45:35) [GCC 9.4.0], pyOpenSSL 23.2.0 (OpenSSL 3.1.1 30 May 2023), cryptography 41.0.1, Platform Linux-5.15.107+-x86_64-with-glibc2.31\n","2023-07-02 09:09:52 [scrapy.utils.log] INFO: Versions: lxml 4.9.2.0, libxml2 2.9.14, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.1, Twisted 22.10.0, Python 3.10.12 (main, Jun  7 2023, 12:45:35) [GCC 9.4.0], pyOpenSSL 23.2.0 (OpenSSL 3.1.1 30 May 2023), cryptography 41.0.1, Platform Linux-5.15.107+-x86_64-with-glibc2.31\n","INFO:scrapy.crawler:Overridden settings:\n","{'LOG_LEVEL': 20, 'USER_AGENT': 'Chrome/97.0'}\n","2023-07-02 09:09:52 [scrapy.crawler] INFO: Overridden settings:\n","{'LOG_LEVEL': 20, 'USER_AGENT': 'Chrome/97.0'}\n","/usr/local/lib/python3.10/dist-packages/scrapy/utils/request.py:232: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.\n","\n","It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.\n","\n","See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.\n","  return cls(crawler)\n","DEBUG:scrapy.utils.log:Using reactor: twisted.internet.epollreactor.EPollReactor\n","INFO:scrapy.extensions.telnet:Telnet Password: 6b9a1aa31fa28f0e\n","2023-07-02 09:09:52 [scrapy.extensions.telnet] INFO: Telnet Password: 6b9a1aa31fa28f0e\n","INFO:scrapy.middleware:Enabled extensions:\n","['scrapy.extensions.corestats.CoreStats',\n"," 'scrapy.extensions.telnet.TelnetConsole',\n"," 'scrapy.extensions.memusage.MemoryUsage',\n"," 'scrapy.extensions.feedexport.FeedExporter',\n"," 'scrapy.extensions.logstats.LogStats']\n","2023-07-02 09:09:52 [scrapy.middleware] INFO: Enabled extensions:\n","['scrapy.extensions.corestats.CoreStats',\n"," 'scrapy.extensions.telnet.TelnetConsole',\n"," 'scrapy.extensions.memusage.MemoryUsage',\n"," 'scrapy.extensions.feedexport.FeedExporter',\n"," 'scrapy.extensions.logstats.LogStats']\n","INFO:scrapy.middleware:Enabled downloader middlewares:\n","['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n"," 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n"," 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n"," 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n"," 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n"," 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n"," 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n"," 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n"," 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n"," 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n"," 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n","2023-07-02 09:09:52 [scrapy.middleware] INFO: Enabled downloader middlewares:\n","['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n"," 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n"," 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n"," 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n"," 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n"," 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n"," 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n"," 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n"," 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n"," 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n"," 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n","INFO:scrapy.middleware:Enabled spider middlewares:\n","['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n"," 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n"," 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n"," 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n"," 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n","2023-07-02 09:09:52 [scrapy.middleware] INFO: Enabled spider middlewares:\n","['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n"," 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n"," 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n"," 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n"," 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n","INFO:scrapy.middleware:Enabled item pipelines:\n","[]\n","2023-07-02 09:09:52 [scrapy.middleware] INFO: Enabled item pipelines:\n","[]\n","INFO:scrapy.core.engine:Spider opened\n","2023-07-02 09:09:52 [scrapy.core.engine] INFO: Spider opened\n","INFO:scrapy.extensions.logstats:Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n","2023-07-02 09:09:52 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n","INFO:scrapy.extensions.telnet:Telnet console listening on 127.0.0.1:6023\n","2023-07-02 09:09:52 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n","DEBUG:scrapy.core.engine:Crawled (200) <GET https://www.booking.com/index.fr.html> (referer: None)\n","INFO:scrapy.core.engine:Closing spider (finished)\n","2023-07-02 09:09:54 [scrapy.core.engine] INFO: Closing spider (finished)\n","INFO:scrapy.statscollectors:Dumping Scrapy stats:\n","{'downloader/request_bytes': 205,\n"," 'downloader/request_count': 1,\n"," 'downloader/request_method_count/GET': 1,\n"," 'downloader/response_bytes': 151325,\n"," 'downloader/response_count': 1,\n"," 'downloader/response_status_count/200': 1,\n"," 'elapsed_time_seconds': 1.376898,\n"," 'finish_reason': 'finished',\n"," 'finish_time': datetime.datetime(2023, 7, 2, 9, 9, 54, 235589),\n"," 'httpcompression/response_bytes': 585232,\n"," 'httpcompression/response_count': 1,\n"," 'log_count/INFO': 10,\n"," 'memusage/max': 158167040,\n"," 'memusage/startup': 158167040,\n"," 'response_received_count': 1,\n"," 'scheduler/dequeued': 1,\n"," 'scheduler/dequeued/memory': 1,\n"," 'scheduler/enqueued': 1,\n"," 'scheduler/enqueued/memory': 1,\n"," 'start_time': datetime.datetime(2023, 7, 2, 9, 9, 52, 858691)}\n","2023-07-02 09:09:54 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n","{'downloader/request_bytes': 205,\n"," 'downloader/request_count': 1,\n"," 'downloader/request_method_count/GET': 1,\n"," 'downloader/response_bytes': 151325,\n"," 'downloader/response_count': 1,\n"," 'downloader/response_status_count/200': 1,\n"," 'elapsed_time_seconds': 1.376898,\n"," 'finish_reason': 'finished',\n"," 'finish_time': datetime.datetime(2023, 7, 2, 9, 9, 54, 235589),\n"," 'httpcompression/response_bytes': 585232,\n"," 'httpcompression/response_count': 1,\n"," 'log_count/INFO': 10,\n"," 'memusage/max': 158167040,\n"," 'memusage/startup': 158167040,\n"," 'response_received_count': 1,\n"," 'scheduler/dequeued': 1,\n"," 'scheduler/dequeued/memory': 1,\n"," 'scheduler/enqueued': 1,\n"," 'scheduler/enqueued/memory': 1,\n"," 'start_time': datetime.datetime(2023, 7, 2, 9, 9, 52, 858691)}\n","INFO:scrapy.core.engine:Spider closed (finished)\n","2023-07-02 09:09:54 [scrapy.core.engine] INFO: Spider closed (finished)\n"]}]}]}