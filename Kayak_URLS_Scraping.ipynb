{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1dzRtgoQ5tDG_dFF5ALHbxF6ZkRY0w32F","authorship_tag":"ABX9TyP5HQxXEk4xQjaK8q5ftq3N"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install scrapy -q"],"metadata":{"id":"2eAKjH7eYum0","executionInfo":{"status":"ok","timestamp":1688283973604,"user_tz":-120,"elapsed":15473,"user":{"displayName":"François Berret","userId":"15987982988001849610"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9afcc68b-c931-4ff4-ea77-f6d1513c9e54"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/277.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m277.2/277.2 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m78.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.0/59.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.0/247.0 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.3/93.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.6/74.6 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"PYUVUId1YGJy","executionInfo":{"status":"ok","timestamp":1688283974631,"user_tz":-120,"elapsed":1034,"user":{"displayName":"François Berret","userId":"15987982988001849610"}}},"outputs":[],"source":["import os\n","import logging\n","\n","import scrapy\n","from scrapy.crawler import CrawlerProcess"]},{"cell_type":"code","source":["cities = [\"Mont Saint Michel\",\n","\"St Malo\",\n","\"Bayeux\",\n","\"Le Havre\",\n","\"Rouen\",\n","\"Paris\",\n","\"Amiens\",\n","\"Lille\",\n","\"Strasbourg\",\n","\"Chateau du Haut Koenigsbourg\",\n","\"Colmar\",\n","\"Eguisheim\",\n","\"Besancon\",\n","\"Dijon\",\n","\"Annecy\",\n","\"Grenoble\",\n","\"Lyon\",\n","\"Gorges du Verdon\",\n","\"Bormes les Mimosas\",\n","\"Cassis\",\n","\"Marseille\",\n","\"Aix en Provence\",\n","\"Avignon\",\n","\"Uzes\",\n","\"Nimes\",\n","\"Aigues Mortes\",\n","\"Saintes Maries de la mer\",\n","\"Collioure\",\n","\"Carcassonne\",\n","\"Ariege\",\n","\"Toulouse\",\n","\"Montauban\",\n","\"Biarritz\",\n","\"Bayonne\",\n","\"La Rochelle\"]"],"metadata":{"id":"h7_pZwaWY4w6","executionInfo":{"status":"ok","timestamp":1688283974632,"user_tz":-120,"elapsed":9,"user":{"displayName":"François Berret","userId":"15987982988001849610"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["class BookingSpider(scrapy.Spider):\n","    name=\"Booking\"\n","    start_urls = ['https://www.booking.com/index.fr.html?label=gen173nr-1FCBkoggI46AdIM1gEaE2IAQGYAQ24ARfIAQzYAQHoAQH4AQKIAgGoAgO4AqzC26EGwAIB0gIkZDY4Zjg5MTMtNTFiMS00ZGMxLWI5MDItNTAyNTNkNTkyYWZj2AIF4AIB&click_from_logo=1']\n","    def parse(self, response):\n","        cities = [\"Mont Saint Michel\",\n","                \"St Malo\",\n","                \"Bayeux\",\n","                \"Le Havre\",\n","                \"Rouen\",\n","                \"Paris\",\n","                \"Amiens\",\n","                \"Lille\",\n","                \"Strasbourg\",\n","                \"Chateau du Haut Koenigsbourg\",\n","                \"Colmar\",\n","                \"Eguisheim\",\n","                \"Besancon\",\n","                \"Dijon\",\n","                \"Annecy\",\n","                \"Grenoble\",\n","                \"Lyon\",\n","                \"Gorges du Verdon\",\n","                \"Bormes les Mimosas\",\n","                \"Cassis\",\n","                \"Marseille\",\n","                \"Aix en Provence\",\n","                \"Avignon\",\n","                \"Uzes\",\n","                \"Nimes\",\n","                \"Aigues Mortes\",\n","                \"Saintes Maries de la mer\",\n","                \"Collioure\",\n","                \"Carcassonne\",\n","                \"Ariege\",\n","                \"Toulouse\",\n","                \"Montauban\",\n","                \"Biarritz\",\n","                \"Bayonne\",\n","                \"La Rochelle\"]\n","        for city in cities:\n","            return scrapy.FormRequest.from_response(\n","                response,\n","                formdata={':Ra9:': \"Collioure\"},\n","                callback=self.after_search\n","            )\n","\n","            def after_search(self, response):\n","                return {\n","                urls : response.xpath('//*[@id=\"bodyconstraint-inner\"]/div[1]/div/div/nav/ol/li[4]/span/a').attrib[\"href\"]\n","                }\n","\n","filename = \"bookingurls.json\"\n","\n","if filename in os.listdir('/content/drive/MyDrive/Jedha_Fullstack/Kayak_Project/'):\n","        os.remove('/content/drive/MyDrive/Jedha_Fullstack/Kayak_Project/' + filename)\n","\n","# Declare a new CrawlerProcess with some settings\n","process = CrawlerProcess(settings = {\n","    'USER_AGENT': 'Chrome/97.0',\n","    'LOG_LEVEL': logging.INFO,\n","    \"FEEDS\": {\n","        '/content/drive/MyDrive/Jedha_Fullstack/Kayak_Project/' + filename: {\"format\": \"json\"},\n","    }\n","})\n","\n","# Start the crawling using the spider you defined above\n","process.crawl(BookingSpider)\n","process.start()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MhC6xMjcZLIq","executionInfo":{"status":"ok","timestamp":1688283977235,"user_tz":-120,"elapsed":2610,"user":{"displayName":"François Berret","userId":"15987982988001849610"}},"outputId":"e5eabbd9-15d0-436a-edd1-da98fec54782"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:scrapy.utils.log:Scrapy 2.9.0 started (bot: scrapybot)\n","2023-07-02 07:46:13 [scrapy.utils.log] INFO: Scrapy 2.9.0 started (bot: scrapybot)\n","INFO:scrapy.utils.log:Versions: lxml 4.9.2.0, libxml2 2.9.14, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.1, Twisted 22.10.0, Python 3.10.12 (main, Jun  7 2023, 12:45:35) [GCC 9.4.0], pyOpenSSL 23.2.0 (OpenSSL 3.1.1 30 May 2023), cryptography 41.0.1, Platform Linux-5.15.107+-x86_64-with-glibc2.31\n","2023-07-02 07:46:13 [scrapy.utils.log] INFO: Versions: lxml 4.9.2.0, libxml2 2.9.14, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.1, Twisted 22.10.0, Python 3.10.12 (main, Jun  7 2023, 12:45:35) [GCC 9.4.0], pyOpenSSL 23.2.0 (OpenSSL 3.1.1 30 May 2023), cryptography 41.0.1, Platform Linux-5.15.107+-x86_64-with-glibc2.31\n","INFO:scrapy.crawler:Overridden settings:\n","{'LOG_LEVEL': 20, 'USER_AGENT': 'Chrome/97.0'}\n","2023-07-02 07:46:13 [scrapy.crawler] INFO: Overridden settings:\n","{'LOG_LEVEL': 20, 'USER_AGENT': 'Chrome/97.0'}\n","/usr/local/lib/python3.10/dist-packages/scrapy/utils/request.py:232: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.\n","\n","It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.\n","\n","See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.\n","  return cls(crawler)\n","DEBUG:scrapy.utils.log:Using reactor: twisted.internet.epollreactor.EPollReactor\n","INFO:scrapy.extensions.telnet:Telnet Password: 1a025ced849f32ec\n","2023-07-02 07:46:13 [scrapy.extensions.telnet] INFO: Telnet Password: 1a025ced849f32ec\n","INFO:scrapy.middleware:Enabled extensions:\n","['scrapy.extensions.corestats.CoreStats',\n"," 'scrapy.extensions.telnet.TelnetConsole',\n"," 'scrapy.extensions.memusage.MemoryUsage',\n"," 'scrapy.extensions.feedexport.FeedExporter',\n"," 'scrapy.extensions.logstats.LogStats']\n","2023-07-02 07:46:13 [scrapy.middleware] INFO: Enabled extensions:\n","['scrapy.extensions.corestats.CoreStats',\n"," 'scrapy.extensions.telnet.TelnetConsole',\n"," 'scrapy.extensions.memusage.MemoryUsage',\n"," 'scrapy.extensions.feedexport.FeedExporter',\n"," 'scrapy.extensions.logstats.LogStats']\n","INFO:scrapy.middleware:Enabled downloader middlewares:\n","['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n"," 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n"," 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n"," 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n"," 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n"," 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n"," 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n"," 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n"," 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n"," 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n"," 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n","2023-07-02 07:46:13 [scrapy.middleware] INFO: Enabled downloader middlewares:\n","['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n"," 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n"," 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n"," 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n"," 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n"," 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n"," 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n"," 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n"," 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n"," 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n"," 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n","INFO:scrapy.middleware:Enabled spider middlewares:\n","['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n"," 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n"," 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n"," 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n"," 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n","2023-07-02 07:46:13 [scrapy.middleware] INFO: Enabled spider middlewares:\n","['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n"," 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n"," 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n"," 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n"," 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n","INFO:scrapy.middleware:Enabled item pipelines:\n","[]\n","2023-07-02 07:46:13 [scrapy.middleware] INFO: Enabled item pipelines:\n","[]\n","INFO:scrapy.core.engine:Spider opened\n","2023-07-02 07:46:13 [scrapy.core.engine] INFO: Spider opened\n","INFO:scrapy.extensions.logstats:Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n","2023-07-02 07:46:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n","INFO:scrapy.extensions.telnet:Telnet console listening on 127.0.0.1:6023\n","2023-07-02 07:46:13 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n","DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): publicsuffix.org:443\n","DEBUG:urllib3.connectionpool:https://publicsuffix.org:443 \"GET /list/public_suffix_list.dat HTTP/1.1\" 200 79181\n","DEBUG:scrapy.core.engine:Crawled (200) <GET https://www.booking.com/index.fr.html?label=gen173nr-1FCBkoggI46AdIM1gEaE2IAQGYAQ24ARfIAQzYAQHoAQH4AQKIAgGoAgO4AqzC26EGwAIB0gIkZDY4Zjg5MTMtNTFiMS00ZGMxLWI5MDItNTAyNTNkNTkyYWZj2AIF4AIB&click_from_logo=1> (referer: None)\n","ERROR:scrapy.core.scraper:Spider error processing <GET https://www.booking.com/index.fr.html?label=gen173nr-1FCBkoggI46AdIM1gEaE2IAQGYAQ24ARfIAQzYAQHoAQH4AQKIAgGoAgO4AqzC26EGwAIB0gIkZDY4Zjg5MTMtNTFiMS00ZGMxLWI5MDItNTAyNTNkNTkyYWZj2AIF4AIB&click_from_logo=1> (referer: None)\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/twisted/internet/defer.py\", line 892, in _runCallbacks\n","    current.result = callback(  # type: ignore[misc]\n","  File \"/usr/local/lib/python3.10/dist-packages/scrapy/spiders/__init__.py\", line 73, in _parse\n","    return self.parse(response, **kwargs)\n","  File \"<ipython-input-4-ec1e4e856e05>\", line 44, in parse\n","    callback=self.after_search\n","AttributeError: 'BookingSpider' object has no attribute 'after_search'\n","2023-07-02 07:46:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.booking.com/index.fr.html?label=gen173nr-1FCBkoggI46AdIM1gEaE2IAQGYAQ24ARfIAQzYAQHoAQH4AQKIAgGoAgO4AqzC26EGwAIB0gIkZDY4Zjg5MTMtNTFiMS00ZGMxLWI5MDItNTAyNTNkNTkyYWZj2AIF4AIB&click_from_logo=1> (referer: None)\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/twisted/internet/defer.py\", line 892, in _runCallbacks\n","    current.result = callback(  # type: ignore[misc]\n","  File \"/usr/local/lib/python3.10/dist-packages/scrapy/spiders/__init__.py\", line 73, in _parse\n","    return self.parse(response, **kwargs)\n","  File \"<ipython-input-4-ec1e4e856e05>\", line 44, in parse\n","    callback=self.after_search\n","AttributeError: 'BookingSpider' object has no attribute 'after_search'\n","INFO:scrapy.core.engine:Closing spider (finished)\n","2023-07-02 07:46:15 [scrapy.core.engine] INFO: Closing spider (finished)\n","INFO:scrapy.statscollectors:Dumping Scrapy stats:\n","{'downloader/request_bytes': 369,\n"," 'downloader/request_count': 1,\n"," 'downloader/request_method_count/GET': 1,\n"," 'downloader/response_bytes': 153381,\n"," 'downloader/response_count': 1,\n"," 'downloader/response_status_count/200': 1,\n"," 'elapsed_time_seconds': 1.689848,\n"," 'finish_reason': 'finished',\n"," 'finish_time': datetime.datetime(2023, 7, 2, 7, 46, 15, 599408),\n"," 'httpcompression/response_bytes': 596883,\n"," 'httpcompression/response_count': 1,\n"," 'log_count/ERROR': 1,\n"," 'log_count/INFO': 10,\n"," 'memusage/max': 155652096,\n"," 'memusage/startup': 155652096,\n"," 'response_received_count': 1,\n"," 'scheduler/dequeued': 1,\n"," 'scheduler/dequeued/memory': 1,\n"," 'scheduler/enqueued': 1,\n"," 'scheduler/enqueued/memory': 1,\n"," 'spider_exceptions/AttributeError': 1,\n"," 'start_time': datetime.datetime(2023, 7, 2, 7, 46, 13, 909560)}\n","2023-07-02 07:46:15 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n","{'downloader/request_bytes': 369,\n"," 'downloader/request_count': 1,\n"," 'downloader/request_method_count/GET': 1,\n"," 'downloader/response_bytes': 153381,\n"," 'downloader/response_count': 1,\n"," 'downloader/response_status_count/200': 1,\n"," 'elapsed_time_seconds': 1.689848,\n"," 'finish_reason': 'finished',\n"," 'finish_time': datetime.datetime(2023, 7, 2, 7, 46, 15, 599408),\n"," 'httpcompression/response_bytes': 596883,\n"," 'httpcompression/response_count': 1,\n"," 'log_count/ERROR': 1,\n"," 'log_count/INFO': 10,\n"," 'memusage/max': 155652096,\n"," 'memusage/startup': 155652096,\n"," 'response_received_count': 1,\n"," 'scheduler/dequeued': 1,\n"," 'scheduler/dequeued/memory': 1,\n"," 'scheduler/enqueued': 1,\n"," 'scheduler/enqueued/memory': 1,\n"," 'spider_exceptions/AttributeError': 1,\n"," 'start_time': datetime.datetime(2023, 7, 2, 7, 46, 13, 909560)}\n","INFO:scrapy.core.engine:Spider closed (finished)\n","2023-07-02 07:46:15 [scrapy.core.engine] INFO: Spider closed (finished)\n"]}]}]}